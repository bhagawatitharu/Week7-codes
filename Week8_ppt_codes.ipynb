{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSqLq_tyoAgO",
        "outputId": "269761e6-5e84-4484-91ec-c8e015ea433b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuXzWKDynhMK",
        "outputId": "4fcf1b3a-24a6-4802-cc70-5cd40f3e50bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load stop words from nltk\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words and apply stemming\n",
        "    tokens = [ps.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def load_and_preprocess_data(directory):\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "    # Load and preprocess each text file\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            label = filename.split('_')[0]  # Assuming labels are in the filename, like 'label_filename.txt'\n",
        "            with open(os.path.join(directory, filename), 'r') as file:\n",
        "                raw_text = file.read()\n",
        "                processed_text = preprocess_text(raw_text)\n",
        "                texts.append(processed_text)\n",
        "                labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "# Example usage\n",
        "data_dir = \"/content/10-Stories\"\n",
        "texts, labels = load_and_preprocess_data(data_dir)\n",
        "\n",
        "# Applying TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def create_inverted_index(texts):\n",
        "    inverted_index = defaultdict(list)\n",
        "\n",
        "    for doc_id, text in enumerate(texts):\n",
        "        words = text.split()\n",
        "        for word in set(words):\n",
        "            inverted_index[word].append(doc_id)\n",
        "\n",
        "    return inverted_index\n",
        "\n",
        "# Create inverted index\n",
        "inverted_index = create_inverted_index(texts)\n",
        "\n",
        "# Check a sample word in the inverted index\n",
        "sample_word = \"ant\"  # Replace with any word that might be in your corpus\n",
        "print(f\"Inverted Index for '{sample_word}':\", inverted_index.get(sample_word, \"Not found\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzm4neano8S2",
        "outputId": "e8a122bc-67d7-4ce2-9e64-b0de4021ccc6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverted Index for 'ant': [0, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def vector_space_model(query, tfidf_vectorizer, X_tfidf):\n",
        "    query_preprocessed = preprocess_text(query)\n",
        "    query_tfidf = tfidf_vectorizer.transform([query_preprocessed])\n",
        "    cosine_similarities = cosine_similarity(query_tfidf, X_tfidf).flatten()\n",
        "\n",
        "    return cosine_similarities\n",
        "\n",
        "# Example query\n",
        "query = \"ant\"\n",
        "query_similarities = vector_space_model(query, tfidf_vectorizer, X_tfidf)\n",
        "\n",
        "# Retrieve top documents\n",
        "top_n = 5\n",
        "top_doc_indices = np.argsort(query_similarities)[-top_n:][::-1]\n",
        "print(\"Top Documents:\", top_doc_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaNvuUaCq0kO",
        "outputId": "957de1fd-727d-4f2d-ef17-110bc3ab8d78"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Documents: [0 8 9 7 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_documents(query, tfidf_vectorizer, X_tfidf, top_n=5):\n",
        "    similarities = vector_space_model(query, tfidf_vectorizer, X_tfidf)\n",
        "    ranked_indices = np.argsort(similarities)[-top_n:][::-1]\n",
        "    return ranked_indices, similarities[ranked_indices]\n",
        "\n",
        "# Example of ranking\n",
        "ranked_docs, scores = rank_documents(\"sample query\", tfidf_vectorizer, X_tfidf)\n",
        "print(f\"Ranked Documents: {ranked_docs}, Scores: {scores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve3LwxRvq2U4",
        "outputId": "b201c5ea-c014-470c-a99b-82e234131a1d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Documents: [9 8 7 6 5], Scores: [0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have binary relevance labels (1 for relevant, 0 for non-relevant)\n",
        "def evaluate_precision_recall(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='binary')\n",
        "    recall = recall_score(y_true, y_pred, average='binary')\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Dummy example of actual vs predicted relevance\n",
        "y_true = [1, 0, 1, 0, 1]  # Actual relevance (binary)\n",
        "y_pred = [1, 0, 1, 0, 0]  # Predicted relevance (binary)\n",
        "\n",
        "precision, recall, f1 = evaluate_precision_recall(y_true, y_pred)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAsa0ApdrDly",
        "outputId": "8147f6bf-df12-41d4-fcd6-4d4f7d0dfe0e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0, Recall: 0.6666666666666666, F1 Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(relevant_docs, retrieved_docs):\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "    for i, doc in enumerate(retrieved_docs):\n",
        "        if doc in relevant_docs:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i + 1.0)\n",
        "\n",
        "    if not relevant_docs:\n",
        "        return 0.0\n",
        "    return score / len(relevant_docs)\n",
        "\n",
        "# Example of MAP calculation\n",
        "relevant_docs = [2, 5, 7]  # Ground truth relevant documents\n",
        "retrieved_docs = [2, 3, 5, 6, 7]  # Retrieved document rankings\n",
        "\n",
        "map_score = mean_average_precision(relevant_docs, retrieved_docs)\n",
        "print(f\"MAP Score: {map_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmDM3HCGrGd3",
        "outputId": "7f460c61-8890-412e-85e4-83baeecff973"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP Score: 0.7555555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg(relevances, k):\n",
        "    def dcg(scores):\n",
        "        return sum([rel / np.log2(idx + 2) for idx, rel in enumerate(scores)])\n",
        "\n",
        "    ideal_relevances = sorted(relevances, reverse=True)\n",
        "    return dcg(relevances[:k]) / dcg(ideal_relevances[:k])\n",
        "\n",
        "# Example relevance scores\n",
        "relevances = [3, 2, 3, 0, 1, 2]  # Example of relevance scores of retrieved docs\n",
        "k = 5\n",
        "print(f\"nDCG: {ndcg(relevances, k)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR8X7jfdrJlJ",
        "outputId": "88e17a05-e321-43cf-85a3-c7b8aa960f1c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nDCG: 0.8610441760375027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DkdiFimrL-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}